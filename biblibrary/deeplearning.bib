@inproceedings{10.5555/2969442.2969628,
  title      = {Learning Structured Output Representation Using Deep Conditional Generative Models},
  booktitle  = {Proceedings of the 29th International Conference on Neural Information Processing Systems - Volume 2},
  author     = {Sohn, Kihyuk and Yan, Xinchen and Lee, Honglak},
  date       = {2015},
  series     = {{{NIPS}}'15},
  pages      = {3483--3491},
  publisher  = {MIT Press},
  location   = {Cambridge, MA, USA},
  pagetotal  = {9},
  annotation = {titleTranslation: 利用深度条件生成模型学习结构化输出表示\\
                abstractTranslation:  有监督的深度学习已经成功应用于许多识别问题。虽然当提供大量的训练数据时，它可以很好地近似复杂的多对一函数，但对复杂的结构化输出表示进行建模，从而有效地进行概率推理并做出多样化的预测仍然具有挑战性。在这项工作中，我们开发了一个使用高斯潜变量的结构化输出预测的深度条件生成模型。该模型在随机梯度变分贝叶斯框架下进行高效训练，并允许使用随机前馈推断进行快速预测。此外，我们提供了新的策略来构建鲁棒的结构化预测算法，例如输入噪声注入和多尺度预测目标化}
}

@inproceedings{10.5555/3295222.3295349,
  title      = {Attention Is All You Need},
  booktitle  = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  author     = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Łukasz and Polosukhin, Illia},
  date       = {2017},
  series     = {{{NIPS}}'17},
  pages      = {6000--6010},
  publisher  = {Curran Associates Inc.},
  location   = {Red Hook, NY, USA},
  isbn       = {978-1-5108-6096-4},
  pagetotal  = {11},
  annotation = {titleTranslation: 注意力是你所需要的一切\\
                abstractTranslation:  占主导地位的序列转导模型是基于复杂的循环或卷积神经网络，包括编码器和解码器。表现最好的模型还通过注意力机制将编码器和解码器连接起来。我们提出了一种新的简单的网络结构，Transformer，它完全基于注意力机制，不需要递归和卷积。在两个机器翻译任务上的实验表明，这些模型在质量上更胜一筹，同时具有更高的可并行性，需要的训练时间也显著减少。我们的模型在WMT 2014英德翻译任务上达到了28.4 BLEU，比现有的最好结果(包括集成)提高了2 BLEU以上。在WMT 2014英法翻译任务上，我们的模型建立了一个}
}

@inproceedings{agarwalComprehensiveReviewLinear2024,
  title      = {A {{Comprehensive Review}} of {{Linear Regression}}, {{Random Forest}}, {{XGBoost}}, and {{SVR}}: {{Integrating Machine Learning}} and {{Actuarial Science}} for {{Health Insurance Pricing}}},
  booktitle  = {Data {{Science}} and {{Security}}},
  author     = {Agarwal, Vedant and Singh, Mehakdeep and Kumar, Kukatlapalli Pradeep},
  date       = {2024},
  pages      = {355--367},
  publisher  = {Springer Nature Singapore},
  location   = {Singapore},
  isbn       = {978-981-9709-75-5},
  annotation = {titleTranslation: 全面回顾了线性回归、随机森林、Xgboost和Svr：整合机器学习和精算学进行健康险定价\\
                abstractTranslation:  精算科学和数据科学正在被研究作为使用物联网、人工智能、大数据和机器学习( ML )算法等工业4.0技术的融合。当分析精算学的早期成分时，本来可以更加准确和快速，但当AI和ML的后期阶段被整合时，算法并没有达到标准，精算师也经历了一些准确性的担忧。公司要求精算师在分析中做到精确，以获得可靠的结果。由于这些公司收集了大量的数据，手动做出的选择可能是错误的。因此，我们将在本文中检验替代模型，作为决策过程的一部分。一旦我们选择了最佳的行动路径，}
}

@inproceedings{choLearningPhraseRepresentations2014,
  title      = {Learning {{Phrase Representations}} Using {{RNN Encoder}}–{{Decoder}} for {{Statistical Machine Translation}}},
  booktitle  = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author     = {Cho, Kyunghyun and Van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  date       = {2014},
  pages      = {1724--1734},
  publisher  = {Association for Computational Linguistics},
  location   = {Doha, Qatar},
  urldate    = {2024-12-30},
  eventtitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  annotation = {titleTranslation: 利用RNN编码器-解码器学习短语表示进行统计机器翻译}
}

@article{elmanFindingStructureTime1990,
  title        = {Finding {{Structure}} in {{Time}}},
  author       = {Elman, Jeffrey L.},
  date         = {1990-03},
  journaltitle = {Cognitive Science},
  shortjournal = {Cognitive Science},
  volume       = {14},
  number       = {2},
  pages        = {179--211},
  urldate      = {2024-12-30},
  annotation   = {titleTranslation: 及时寻找结构，RNN原始文献\\
                  }
}

@article{galtonRegressionMediocrityHereditary1886,
  title        = {Regression towards Mediocrity in Hereditary Stature.},
  author       = {Galton, Francis},
  date         = {1886},
  journaltitle = {The Journal of the Anthropological Institute of Great Britain and Ireland},
  shortjournal = {The Journal of the Anthropological Institute of Great Britain and Ireland},
  volume       = {15},
  pages        = {246--263},
  publisher    = {JSTOR},
  annotation   = {titleTranslation: 在遗传性身材上向平庸回归。}
}

@book{Goodfellow-et-al-2016,
  title      = {Deep Learning},
  author     = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date       = {2016},
  publisher  = {MIT Press},
  annotation = {titleTranslation: 深度学习}
}

@article{karlMultiObjectiveHyperparameterOptimization2023,
  title        = {Multi-{{Objective Hyperparameter Optimization}} in {{Machine Learning}}—{{An Overview}}},
  author       = {Karl, Florian and Pielok, Tobias and Moosbauer, Julia and Pfisterer, Florian and Coors, Stefan and Binder, Martin and Schneider, Lennart and Thomas, Janek and Richter, Jakob and Lang, Michel and Garrido-Merchán, Eduardo C. and Branke, Juergen and Bischl, Bernd},
  date         = {2023-12-31},
  journaltitle = {ACM Transactions on Evolutionary Learning and Optimization},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  volume       = {3},
  number       = {4},
  pages        = {1--50},
  annotation   = {abstractTranslation:  超参数优化是典型的现代机器学习( ML )工作流的重要组成部分。这是因为ML方法和相应的预处理步骤往往只有在适当调整超参数时才能获得最优的性能。但在许多应用中，我们不仅仅只对优化ML流水线以提高预测精度感兴趣；在确定最优配置时，必须考虑额外的度量或约束，从而导致多目标优化问题。由于缺乏多目标超参数优化的知识和容易获得的软件实现，这在实际中常常被忽视。在这项工作中，我们向读者介绍了多目标超参数优化的基础知识，并激励了它的u\\
                  titleTranslation: 机器学习中的多目标超参数优化- -综述}
}

@article{xuSmallDataMachine2023,
  title        = {Small Data Machine Learning in Materials Science},
  author       = {family=Xu, given=PC, given-i=PC and family=Ji, given=XB, given-i=XB and family=Li, given=MJ, given-i=MJ and family=Lu, given=WC, given-i=WC},
  date         = {2023-03-25},
  journaltitle = {NPJ COMPUTATIONAL MATERIALS},
  volume       = {9},
  number       = {1},
  keywords     = {DESIGN,DISCOVERY,DRIVEN,METHODOLOGIES,PLATFORM,RECOGNITION},
  annotation   = {abstractTranslation:  本综述讨论了材料机器学习面临的小数据困境。首先，我们分析了小数据带来的局限性。然后，介绍了材料机器学习的工作流程。接下来介绍了处理小数据的方法，包括从出版物中提取数据、构建材料数据库、高通量计算以及从数据源层面进行实验；从算法层面对小数据和不平衡学习的算法进行建模；从机器学习策略层面进行主动学习和迁移学习。最后，提出了小数据机器学习在材料科学领域的未来发展方向。\\
                  titleTranslation: 材料科学中的小数据机器学习}
}

@article{uesaka1973theory,
  title     = {A theory of learnability},
  author    = {Uesaka, Yoshinori and Aizawa, Teruaki and Ebara, Terumasa and Ozeki, Kazuhiko},
  journal   = {Kybernetik},
  volume    = {13},
  pages     = {123--131},
  year      = {1973},
  publisher = {Springer}
}

@article{liu2021self,
  title     = {Self-supervised learning: Generative or contrastive},
  author    = {Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Mian, Li and Wang, Zhaoyu and Zhang, Jing and Tang, Jie},
  journal   = {IEEE transactions on knowledge and data engineering},
  volume    = {35},
  number    = {1},
  pages     = {857--876},
  year      = {2021},
  publisher = {IEEE}
}

@article{cortes1995support,
  title   = {Support-Vector Networks},
  author  = {Cortes, Corinna},
  journal = {Machine Learning},
  year    = {1995},
  volume  = {20},
  pages   = {273--297}
}

@article{cover1967nearest,
  title     = {Nearest neighbor pattern classification},
  author    = {Cover, Thomas and Hart, Peter},
  journal   = {IEEE transactions on information theory},
  volume    = {13},
  number    = {1},
  pages     = {21--27},
  year      = {1967},
  publisher = {IEEE}
}

@article{quinlan1986induction,
  title     = {Induction of decision trees},
  author    = {Quinlan, J. Ross},
  journal   = {Machine learning},
  volume    = {1},
  pages     = {81--106},
  year      = {1986},
  publisher = {Springer}
}

@article{breiman2001random,
  title     = {Random forests},
  author    = {Breiman, Leo},
  journal   = {Machine learning},
  volume    = {45},
  pages     = {5--32},
  year      = {2001},
  publisher = {Springer}
}

@article{wang2023scientific,
  title     = {Scientific discovery in the age of artificial intelligence},
  author    = {Wang, Hanchen and Fu, Tianfan and Du, Yuanqi and Gao, Wenhao and Huang, Kexin and Liu, Ziming and Chandak, Payal and Liu, Shengchao and Van Katwyk, Peter and Deac, Andreea and others},
  journal   = {Nature},
  volume    = {620},
  number    = {7972},
  pages     = {47--60},
  year      = {2023},
  publisher = {Nature Publishing Group UK London}
}

@article{Xie2023,
  author  = {Xie, Yaochen and Xu, Zhao and Zhang, Jingtun and Wang, Zhengyang and Ji, Shuiwang},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title   = {Self-Supervised Learning of Graph Neural Networks: A Unified Review},
  year    = {2023},
  volume  = {45},
  number  = {2},
  pages   = {2412-2429}
}

@article{choudhary2022recent,
  title     = {Recent advances and applications of deep learning methods in materials science},
  author    = {Choudhary, Kamal and DeCost, Brian and Chen, Chi and Jain, Anubhav and Tavazza, Francesca and Cohn, Ryan and Park, Cheol Woo and Choudhary, Alok and Agrawal, Ankit and Billinge, Simon JL and others},
  journal   = {npj Computational Materials},
  volume    = {8},
  number    = {1},
  pages     = {59},
  year      = {2022},
  publisher = {Nature Publishing Group UK London}
}

@article{yang2023diffusion,
  title     = {Diffusion models: A comprehensive survey of methods and applications},
  author    = {Yang, Ling and Zhang, Zhilong and Song, Yang and Hong, Shenda and Xu, Runsheng and Zhao, Yue and Zhang, Wentao and Cui, Bin and Yang, Ming-Hsuan},
  journal   = {ACM Computing Surveys},
  volume    = {56},
  number    = {4},
  pages     = {1--39},
  year      = {2023},
  publisher = {ACM New York, NY, USA}
}

@article{xu2023multimodal,
  title     = {Multimodal learning with transformers: A survey},
  author    = {Xu, Peng and Zhu, Xiatian and Clifton, David A},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume    = {45},
  number    = {10},
  pages     = {12113--12132},
  year      = {2023},
  publisher = {IEEE}
}

@article{Zhu2024Vision,
  author  = {Zhu, Ye and Wu, Yu and Sebe, Nicu and Yan, Yan},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title   = {Vision + X: A Survey on Multimodal Learning in the Light of Data},
  year    = {2024},
  volume  = {46},
  number  = {12},
  pages   = {9102-9122}
}

@article{biamonte2017quantum,
  title     = {Quantum machine learning},
  author    = {Biamonte, Jacob and Wittek, Peter and Pancotti, Nicola and Rebentrost, Patrick and Wiebe, Nathan and Lloyd, Seth},
  journal   = {Nature},
  volume    = {549},
  number    = {7671},
  pages     = {195--202},
  year      = {2017},
  publisher = {Nature Publishing Group UK London}
}

@book{bufano2023machine,
  title     = {Machine Learning for Astrophysics: Proceedings of the ML4Astro International Conference 30 May-1 Jun 2022},
  author    = {Bufano, Filomena and Riggi, Simone and Sciacca, Eva and Schilliro, Francesco},
  volume    = {60},
  year      = {2023},
  publisher = {Springer Nature}
}